{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8998930d-d13b-4357-b6c1-7ac6f996291c",
   "metadata": {},
   "source": [
    "## Natural Language Processing (NLP) using NLTK and SpaCy modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302b1b88-3b3c-469d-aec9-2ee5dadbfd2a",
   "metadata": {},
   "source": [
    "#### Install packages into Python environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab63c233-a871-4cc0-b2d5-c20f456c1395",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install nltk\n",
    "!pip install textblob\n",
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6df402-4d91-451d-bb0b-76c708ed5b1b",
   "metadata": {},
   "source": [
    "#### import modules from packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf069ae1-1bcc-4231-a0d2-82fb44749e4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from text.blob import TextBlob as tb (would get all of TextBlob)\n",
    "#from BeautifulSoup import BeautifulSoup (would get all of BeautifulSoup)\n",
    "#from nltk.stem.porter import PorterStemmer\n",
    "# from nltk.stem.lancaster import LancasterStemmer\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\t#IMPORT STOPWORDS CORPUS (have to get into lowercase)\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "st = LancasterStemmer()\n",
    "from textblob import Word\n",
    "import codecs\n",
    "codecs.open\n",
    "import io\n",
    "io.open\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ba0a33-6f69-4bf4-9331-782c47572965",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert a collection of raw documents to a matrix of TF-IDF features.\n",
    "#TF-IDF: Text Frequency-Inverse Document Frequency weights\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deea188a-cf1b-4eac-9dd6-0b3f44345d9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to remove html tags from a html file\n",
    "def stripAllTags( html ):\n",
    "        if html is None:\n",
    "                return None\n",
    "        return ''.join( BeautifulSoup( html ).findAll( text = True ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f28ff7-6c8b-4d88-907c-7b814a0bdcdb",
   "metadata": {},
   "source": [
    "[SpaCy](https://spacy.io)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d119587-b798-4fe9-ac7f-39b7a4decd0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea7a240-19fd-4bb7-8e24-0c94429cbe35",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c4c6bc-4303-4769-9bd1-7ed813b34205",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c581c3-e279-4c7b-8699-71c7790225ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ef9858-9856-4582-9de1-892a8288e15d",
   "metadata": {},
   "source": [
    "![alt text](spacy_lem.png \"SpaCy tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178de338-d5e6-4377-ab64-13ec4af67edb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f676922c-60db-4e26-9264-836fe6eab5c4",
   "metadata": {},
   "source": [
    "### Example: Process full document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101cb390-b9e8-4563-b71e-43f46d49561f",
   "metadata": {},
   "source": [
    "Example using SpaCy to process entire document\n",
    "Here we are iterating through the nouns and verbs using the method noun_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0a6a77-da37-4b63-a40c-18470aae2154",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Process whole documents\n",
    "text = (\"When Sebastian Thrun started working on self-driving cars at \"\n",
    "        \"Google in 2007, few people outside of the company took him \"\n",
    "        \"seriously. “I can tell you very senior CEOs of major American \"\n",
    "        \"car companies would shake my hand and turn away because I wasn’t \"\n",
    "        \"worth talking to,” said Thrun, in an interview with Recode earlier \"\n",
    "        \"this week.\")\n",
    "doc = nlp(text)\n",
    "\n",
    "# Analyze syntax\n",
    "print(\"Noun phrases:\", [chunk.text for chunk in doc.noun_chunks])\n",
    "print(\"Verbs:\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"])\n",
    "\n",
    "# Find named entities, phrases and concepts\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b58c05f-4635-4555-a4d2-01740a605a18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#generate a list of nouns\n",
    "[chunk.text for chunk in doc.noun_chunks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3666f9c-e410-497d-9572-5a243fc47564",
   "metadata": {},
   "source": [
    "##### Scanning text for parts of speech (pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16f399c-d663-4c46-9dcf-3e46bdbc30c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbcf71c-203f-45d6-b257-a9eb7e9a753f",
   "metadata": {},
   "source": [
    "#### load large model and define function to clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960027af-72d5-435c-9244-0c364975d248",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fdcd84-8999-424e-a8ec-45569bf190f8",
   "metadata": {},
   "source": [
    "#### Function definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c143a3-5398-4c5d-b6dc-3aa4da7078d1",
   "metadata": {},
   "source": [
    "Function below makes text lowercase, removes stopwords (shown below), removes punctuation, and pronouns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c265439-3178-48d0-b060-5d93187edd17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    doc = nlp(text.lower())\n",
    "    result = []\n",
    "    for token in doc:\n",
    "        if token.text in nlp.Defaults.stop_words:\n",
    "            continue\n",
    "        if token.is_punct:\n",
    "            continue\n",
    "        if token.lemma_ == '-PRON-':\n",
    "            continue\n",
    "        result.append(token.lemma_)\n",
    "    return \" \".join(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8d35ff-775e-4580-9b76-5f643dde92b2",
   "metadata": {},
   "source": [
    "#### show stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce37675c-fcd4-4c68-8d72-d9c257ec7db9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c73995-dd56-4161-a2f6-abc7020be127",
   "metadata": {},
   "source": [
    "### Example descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b15a2d-1aaa-40b3-8a21-0aed99c17f39",
   "metadata": {},
   "source": [
    "#### note: RecargaPay and Cardup are startups in Mastercard Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd17ffd9-6ce5-4c96-9db5-ba86e05e919d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recargapay = 'RecargaPay is a Brazilian company that offers a mobile payment platform and wallet. \\\n",
    "It aims to simplify daily transactions such as mobile top-ups, bill payments, gift cards and more.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fef01a-9290-4c95-aee9-f86a362f0ca6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cardup = 'CardUp is a platform that enables users to pay for big-ticket items, such as rent and insurance,  \\\n",
    "sans friction by using a credit card. With each payment, users earn points and miles. \\\n",
    "Users can unlock additional benefits such as discounted house moving services, free rent for a month, or vouchers for school supplies. \\\n",
    "Uses sign up, schedule their payment, Cardup makes the payment for the specified amount plus a processing fee, \\\n",
    "and the user receives a notification when the payment is made.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b590f50b-b76f-4683-ad5b-75d83f8ea33e",
   "metadata": {},
   "source": [
    "#### Text similarity with and without clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d370f5-26a9-4bb2-a7f3-2158da587189",
   "metadata": {},
   "source": [
    "Cosine similarity *without* applying clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8711a9-9d6e-4afd-ba29-b168afaba696",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp(cardup).similarity(nlp(recargapay))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5b380b-3896-430a-811e-e2ac3b8e5b5e",
   "metadata": {},
   "source": [
    "Cosine similarity applying clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a03243-eb0e-495a-bd72-9d8c6eed33ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp(clean(cardup)).similarity(nlp(clean(recargapay)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e9c868-4beb-4da0-b947-67d2d6b55188",
   "metadata": {},
   "source": [
    "#### now add another to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e1d4cd-3753-4596-8a91-7f0cf46117a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tink = 'Tink enables banks to become data-driven, capture the opportunities of open banking, \\\n",
    "and deliver a more personal, intelligent financial experience to their users. Tink provides APIs \\\n",
    "as building blocks to create banking services. The company\\'s products include account aggregation, \\\n",
    "categorization, payment initiation, and personal finance management.On June 24th, 2021, \\\n",
    "Tink was acquired by Visa at a valuation of $2.15B.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f57d645-037a-4ea0-b500-a9dd379cfb96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp(cardup).similarity(nlp(tink))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f391de50-a460-4077-89fd-c9991eb35230",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp(recargapay).similarity(nlp(tink))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49abaaaa-5906-4a24-9d25-771415c2b8ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp(clean(recargapay)).similarity(nlp(clean(tink)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e3b412-c20f-481e-8c0d-0f05bafef0bf",
   "metadata": {},
   "source": [
    "#### Another example: Brown dogs, orange dogs, and startups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60817301-d9e3-4e4a-a322-e794a54399f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "browndog = 'the quick brown dog goes to the zoo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85cd04e-1aa8-45c9-abbb-f533530fd457",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "orangedog = 'Phineas is a dog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfb0c6c-c14e-4e07-9541-17e091ac2e1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "orangedog2 = 'the dog Phineas is orange'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c501a603-1f88-4212-aef4-08b624b0ec64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp(orangedog).similarity(nlp(browndog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f355231d-3637-4156-b571-e12ec72b0e3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean(orangedog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016109ca-5c3e-4d14-a361-6644c321867e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean(browndog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f3d08a-5266-4e59-899a-2dbe665dfd43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean(orangedog2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dfd802-7723-4808-8814-afd14fda3bd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp(clean(orangedog)).similarity(nlp(clean(browndog)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab19f53-0df9-4d61-9a2b-60b83456d71e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp(cardup).similarity(nlp(browndog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e933a4d1-8942-48ce-b823-564cd0df5984",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp(clean(cardup)).similarity(nlp(clean(browndog)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea7e718-aed0-4850-b0a2-861e4c439514",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp(cardup).similarity(nlp(orangedog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b3e1b7-810d-4d50-a48c-107fcb2dee5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp(clean(cardup)).similarity(nlp(clean(orangedog)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022e0b7e-712b-4c6d-9fd5-73ab38038c4b",
   "metadata": {},
   "source": [
    "#### Exercise: Now try comparing two texts yourself.\n",
    "- add in text in place of elipses (...) below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8646208f-b22e-4839-ae1a-b9b8f9aedef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1eed44-e26d-451e-ad51-6d9de2cdbb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f431b8-7c0c-4977-b7c7-617db626517e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp(text1).similarity(nlp(text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87f84b3-64b7-44c7-8f31-448f2abda917",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp(clean(text1)).similarity(nlp(clean(text2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e93356-1ab4-4c34-83c4-16ede187f108",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d53c5f-c86b-4f07-8f11-407e3f08c20d",
   "metadata": {},
   "source": [
    "#### note: Hyro is a startup in Deloitte Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b79a623-8aaa-47c2-8f97-bc8211300e71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyro = 'Hyro provides a conversational AI program that \\\n",
    "           allows businesses to better interact with customers. \\\n",
    "           Through machine learning, the program keeps customer engagement \\\n",
    "           at a high level and optimizes digital interactions.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833d0847-863a-4f82-a4a4-010912d4b50f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp(clean(hyro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4515a5-a0c9-4af7-9601-88f3b013ce3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp(cardup).similarity(nlp(hyro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faf96ca-1497-48f0-8b5e-1c13c303c0ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp(clean(cardup)).similarity(nlp(clean(hyro)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e058da10-f26e-4cfa-ab76-55a8e935a69a",
   "metadata": {},
   "source": [
    "## Research example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c50031d-fc3c-4ec3-b5d7-288728d9daeb",
   "metadata": {},
   "source": [
    "#### note: this function was also defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72a7136-676a-4e5c-a18d-0e6e99c7e7c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    doc = nlp(text.lower())\n",
    "    result = []\n",
    "    for token in doc:\n",
    "        if token.text in nlp.Defaults.stop_words:\n",
    "            continue\n",
    "        if token.is_punct:\n",
    "            continue\n",
    "        if token.lemma_ == '-PRON-':\n",
    "            continue\n",
    "        result.append(token.lemma_)\n",
    "    return \" \".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ccce93-e8c3-443e-8fda-96aba39865e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Files\n",
    "file=\"nordeavc.csv\"\n",
    "file=\"nordeaacc.csv\"\n",
    "df=pd.read_csv(file, sep=',').fillna(value = 0)\n",
    "print(df['Description'][1])\n",
    "df['Description_processed'] = df['Description'].apply(lambda x: clean(x))\n",
    "print('\\nDescription with punctuation and stopwords---\\n_______________________')\n",
    "print(df['Description_processed'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde87b8d-5f4b-438c-a659-0b9a14acd65a",
   "metadata": {},
   "source": [
    "### Now process all companies in portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cb1dfa-1262-4bb5-9ff2-fe94fee249f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shape=df.shape\n",
    "n=shape[0] #number of rows\n",
    "score=np.zeros((n,n)) #making array with scores, set to 0 to start\n",
    "ix=range(0,n) #index 0 to n\n",
    "cix=list(combinations(ix, 2)) #all possible combinations\n",
    "# print(cix)\n",
    "num=len(cix)\n",
    "slist=[] #empty list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d1849f-1927-419f-93c0-3d6ec890b636",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, j in cix:\n",
    "    desc1 = nlp(clean(df['Description_processed'][i]))\n",
    "    desc2 = nlp(clean(df['Description_processed'][j]))\n",
    "    score[i,j]=desc1.similarity(desc2)\n",
    "    slist.append(desc1.similarity(desc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac34e3b-571f-404e-84f0-254f86f79afd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Score matrix: \",score.shape)\n",
    "print(\"\\n\",score[0,0],score[0,1])\n",
    "# Want all the cross scores without double counting then draw histogram and stats\n",
    "dfscore= pd.DataFrame(slist) \n",
    "stats_numeric = dfscore.describe()\n",
    "print(\"Statistics\")\n",
    "print (stats_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ea4fd3-1ae7-478b-afce-18ec4851a2f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136ad17a-7acb-4d7a-8fe5-819529418556",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m, bins, patches = plt.hist(x=slist, bins=25, color='#0504aa',\n",
    "                            alpha=0.7, rwidth=0.85)\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.xlim(0,1.0)\n",
    "plt.xticks(np.arange(0, 1, step=0.1))\n",
    "plt.xlabel('cosine similarity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title(file)\n",
    "#plt.text(23, 45, r'$\\mu=15, b=3$')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56748d9-5145-4c73-a7de-e2982a6bfd90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
